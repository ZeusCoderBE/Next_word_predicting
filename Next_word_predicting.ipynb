{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import Library "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential \n",
    "from tensorflow.keras.layers import Embedding, SimpleRNN, Dense \n",
    "from tensorflow.keras.preprocessing.text import Tokenizer \n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences \n",
    "from sklearn.metrics  import accuracy_score,f1_score,precision_score,recall_score\n",
    "from keras.activations import relu\n",
    "from keras.utils import to_categorical\n",
    "import numpy as np \n",
    "import regex as re \n",
    "np.set_printoptions(threshold=np.inf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Proprocesing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1. Read the file and divide it into sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "def file_to_sentence_list(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        text = file.read()\n",
    "    sentences = [sentence.strip() for sentence in re.split(r'(?<=[.!?])\\s+', text) if sentence.strip()]\n",
    "    return sentences "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2. Create a dictionary for each word in the text file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Ho Chi Minh City University of Technology and Education, with a long and prestigious history in the field of education and research, is a modern school with a rich and diverse learning and research environment.', 'Located in the city center, Ho Chi Minh City University of Technology and Education is not only a provider of professional knowledge but also a vibrant and creative academic community.', 'With modern facilities, classrooms, laboratories and libraries are fully equipped, creating favorable conditions for students and lecturers in the learning and research process.', 'The school is also proud of its team of experienced, highly qualified lecturers who are committed to providing students with the best support and development.', 'Training programs are diverse, flexible and reflect the actual needs of the labor market, giving students the opportunity to develop themselves and prepare for their future careers.', 'In addition, the school also promotes international research and cooperation, creating conditions for students to participate in research projects and exchange with students and lecturers from universities around the world.', '.', 'In short, the University of Technical Education is an ideal learning and research environment, where creativity and discovery are awakened and developed.']\n",
      "{'and': 1, 'the': 2, 'of': 3, 'in': 4, 'research': 5, 'with': 6, 'a': 7, 'students': 8, 'education': 9, 'is': 10, 'are': 11, 'city': 12, 'university': 13, 'school': 14, 'learning': 15, 'also': 16, 'for': 17, 'lecturers': 18, 'to': 19, 'ho': 20, 'chi': 21, 'minh': 22, 'technology': 23, 'modern': 24, 'diverse': 25, 'environment': 26, 'creating': 27, 'conditions': 28, 'long': 29, 'prestigious': 30, 'history': 31, 'field': 32, 'rich': 33, 'located': 34, 'center': 35, 'not': 36, 'only': 37, 'provider': 38, 'professional': 39, 'knowledge': 40, 'but': 41, 'vibrant': 42, 'creative': 43, 'academic': 44, 'community': 45, 'facilities': 46, 'classrooms': 47, 'laboratories': 48, 'libraries': 49, 'fully': 50, 'equipped': 51, 'favorable': 52, 'process': 53, 'proud': 54, 'its': 55, 'team': 56, 'experienced': 57, 'highly': 58, 'qualified': 59, 'who': 60, 'committed': 61, 'providing': 62, 'best': 63, 'support': 64, 'development': 65, 'training': 66, 'programs': 67, 'flexible': 68, 'reflect': 69, 'actual': 70, 'needs': 71, 'labor': 72, 'market': 73, 'giving': 74, 'opportunity': 75, 'develop': 76, 'themselves': 77, 'prepare': 78, 'their': 79, 'future': 80, 'careers': 81, 'addition': 82, 'promotes': 83, 'international': 84, 'cooperation': 85, 'participate': 86, 'projects': 87, 'exchange': 88, 'from': 89, 'universities': 90, 'around': 91, 'world': 92, 'short': 93, 'technical': 94, 'an': 95, 'ideal': 96, 'where': 97, 'creativity': 98, 'discovery': 99, 'awakened': 100, 'developed': 101}\n"
     ]
    }
   ],
   "source": [
    "file_path = 'train.txt'\n",
    "text_data = file_to_sentence_list(file_path)\n",
    "print(text_data)\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(text_data) \n",
    "total_words = len(tokenizer.word_index) + 1\n",
    "print(tokenizer.word_index)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3. Create Input "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[20, 21], [20, 21, 22], [20, 21, 22, 12], [20, 21, 22, 12, 13], [20, 21, 22, 12, 13, 3], [20, 21, 22, 12, 13, 3, 23], [20, 21, 22, 12, 13, 3, 23, 1], [20, 21, 22, 12, 13, 3, 23, 1, 9], [20, 21, 22, 12, 13, 3, 23, 1, 9, 6], [20, 21, 22, 12, 13, 3, 23, 1, 9, 6, 7], [20, 21, 22, 12, 13, 3, 23, 1, 9, 6, 7, 29], [20, 21, 22, 12, 13, 3, 23, 1, 9, 6, 7, 29, 1], [20, 21, 22, 12, 13, 3, 23, 1, 9, 6, 7, 29, 1, 30], [20, 21, 22, 12, 13, 3, 23, 1, 9, 6, 7, 29, 1, 30, 31], [20, 21, 22, 12, 13, 3, 23, 1, 9, 6, 7, 29, 1, 30, 31, 4], [20, 21, 22, 12, 13, 3, 23, 1, 9, 6, 7, 29, 1, 30, 31, 4, 2], [20, 21, 22, 12, 13, 3, 23, 1, 9, 6, 7, 29, 1, 30, 31, 4, 2, 32], [20, 21, 22, 12, 13, 3, 23, 1, 9, 6, 7, 29, 1, 30, 31, 4, 2, 32, 3], [20, 21, 22, 12, 13, 3, 23, 1, 9, 6, 7, 29, 1, 30, 31, 4, 2, 32, 3, 9], [20, 21, 22, 12, 13, 3, 23, 1, 9, 6, 7, 29, 1, 30, 31, 4, 2, 32, 3, 9, 1], [20, 21, 22, 12, 13, 3, 23, 1, 9, 6, 7, 29, 1, 30, 31, 4, 2, 32, 3, 9, 1, 5], [20, 21, 22, 12, 13, 3, 23, 1, 9, 6, 7, 29, 1, 30, 31, 4, 2, 32, 3, 9, 1, 5, 10], [20, 21, 22, 12, 13, 3, 23, 1, 9, 6, 7, 29, 1, 30, 31, 4, 2, 32, 3, 9, 1, 5, 10, 7], [20, 21, 22, 12, 13, 3, 23, 1, 9, 6, 7, 29, 1, 30, 31, 4, 2, 32, 3, 9, 1, 5, 10, 7, 24], [20, 21, 22, 12, 13, 3, 23, 1, 9, 6, 7, 29, 1, 30, 31, 4, 2, 32, 3, 9, 1, 5, 10, 7, 24, 14], [20, 21, 22, 12, 13, 3, 23, 1, 9, 6, 7, 29, 1, 30, 31, 4, 2, 32, 3, 9, 1, 5, 10, 7, 24, 14, 6], [20, 21, 22, 12, 13, 3, 23, 1, 9, 6, 7, 29, 1, 30, 31, 4, 2, 32, 3, 9, 1, 5, 10, 7, 24, 14, 6, 7], [20, 21, 22, 12, 13, 3, 23, 1, 9, 6, 7, 29, 1, 30, 31, 4, 2, 32, 3, 9, 1, 5, 10, 7, 24, 14, 6, 7, 33], [20, 21, 22, 12, 13, 3, 23, 1, 9, 6, 7, 29, 1, 30, 31, 4, 2, 32, 3, 9, 1, 5, 10, 7, 24, 14, 6, 7, 33, 1], [20, 21, 22, 12, 13, 3, 23, 1, 9, 6, 7, 29, 1, 30, 31, 4, 2, 32, 3, 9, 1, 5, 10, 7, 24, 14, 6, 7, 33, 1, 25], [20, 21, 22, 12, 13, 3, 23, 1, 9, 6, 7, 29, 1, 30, 31, 4, 2, 32, 3, 9, 1, 5, 10, 7, 24, 14, 6, 7, 33, 1, 25, 15], [20, 21, 22, 12, 13, 3, 23, 1, 9, 6, 7, 29, 1, 30, 31, 4, 2, 32, 3, 9, 1, 5, 10, 7, 24, 14, 6, 7, 33, 1, 25, 15, 1], [20, 21, 22, 12, 13, 3, 23, 1, 9, 6, 7, 29, 1, 30, 31, 4, 2, 32, 3, 9, 1, 5, 10, 7, 24, 14, 6, 7, 33, 1, 25, 15, 1, 5], [20, 21, 22, 12, 13, 3, 23, 1, 9, 6, 7, 29, 1, 30, 31, 4, 2, 32, 3, 9, 1, 5, 10, 7, 24, 14, 6, 7, 33, 1, 25, 15, 1, 5, 26], [34, 4], [34, 4, 2], [34, 4, 2, 12], [34, 4, 2, 12, 35], [34, 4, 2, 12, 35, 20], [34, 4, 2, 12, 35, 20, 21], [34, 4, 2, 12, 35, 20, 21, 22], [34, 4, 2, 12, 35, 20, 21, 22, 12], [34, 4, 2, 12, 35, 20, 21, 22, 12, 13], [34, 4, 2, 12, 35, 20, 21, 22, 12, 13, 3], [34, 4, 2, 12, 35, 20, 21, 22, 12, 13, 3, 23], [34, 4, 2, 12, 35, 20, 21, 22, 12, 13, 3, 23, 1], [34, 4, 2, 12, 35, 20, 21, 22, 12, 13, 3, 23, 1, 9], [34, 4, 2, 12, 35, 20, 21, 22, 12, 13, 3, 23, 1, 9, 10], [34, 4, 2, 12, 35, 20, 21, 22, 12, 13, 3, 23, 1, 9, 10, 36], [34, 4, 2, 12, 35, 20, 21, 22, 12, 13, 3, 23, 1, 9, 10, 36, 37], [34, 4, 2, 12, 35, 20, 21, 22, 12, 13, 3, 23, 1, 9, 10, 36, 37, 7], [34, 4, 2, 12, 35, 20, 21, 22, 12, 13, 3, 23, 1, 9, 10, 36, 37, 7, 38], [34, 4, 2, 12, 35, 20, 21, 22, 12, 13, 3, 23, 1, 9, 10, 36, 37, 7, 38, 3], [34, 4, 2, 12, 35, 20, 21, 22, 12, 13, 3, 23, 1, 9, 10, 36, 37, 7, 38, 3, 39], [34, 4, 2, 12, 35, 20, 21, 22, 12, 13, 3, 23, 1, 9, 10, 36, 37, 7, 38, 3, 39, 40], [34, 4, 2, 12, 35, 20, 21, 22, 12, 13, 3, 23, 1, 9, 10, 36, 37, 7, 38, 3, 39, 40, 41], [34, 4, 2, 12, 35, 20, 21, 22, 12, 13, 3, 23, 1, 9, 10, 36, 37, 7, 38, 3, 39, 40, 41, 16], [34, 4, 2, 12, 35, 20, 21, 22, 12, 13, 3, 23, 1, 9, 10, 36, 37, 7, 38, 3, 39, 40, 41, 16, 7], [34, 4, 2, 12, 35, 20, 21, 22, 12, 13, 3, 23, 1, 9, 10, 36, 37, 7, 38, 3, 39, 40, 41, 16, 7, 42], [34, 4, 2, 12, 35, 20, 21, 22, 12, 13, 3, 23, 1, 9, 10, 36, 37, 7, 38, 3, 39, 40, 41, 16, 7, 42, 1], [34, 4, 2, 12, 35, 20, 21, 22, 12, 13, 3, 23, 1, 9, 10, 36, 37, 7, 38, 3, 39, 40, 41, 16, 7, 42, 1, 43], [34, 4, 2, 12, 35, 20, 21, 22, 12, 13, 3, 23, 1, 9, 10, 36, 37, 7, 38, 3, 39, 40, 41, 16, 7, 42, 1, 43, 44], [34, 4, 2, 12, 35, 20, 21, 22, 12, 13, 3, 23, 1, 9, 10, 36, 37, 7, 38, 3, 39, 40, 41, 16, 7, 42, 1, 43, 44, 45], [6, 24], [6, 24, 46], [6, 24, 46, 47], [6, 24, 46, 47, 48], [6, 24, 46, 47, 48, 1], [6, 24, 46, 47, 48, 1, 49], [6, 24, 46, 47, 48, 1, 49, 11], [6, 24, 46, 47, 48, 1, 49, 11, 50], [6, 24, 46, 47, 48, 1, 49, 11, 50, 51], [6, 24, 46, 47, 48, 1, 49, 11, 50, 51, 27], [6, 24, 46, 47, 48, 1, 49, 11, 50, 51, 27, 52], [6, 24, 46, 47, 48, 1, 49, 11, 50, 51, 27, 52, 28], [6, 24, 46, 47, 48, 1, 49, 11, 50, 51, 27, 52, 28, 17], [6, 24, 46, 47, 48, 1, 49, 11, 50, 51, 27, 52, 28, 17, 8], [6, 24, 46, 47, 48, 1, 49, 11, 50, 51, 27, 52, 28, 17, 8, 1], [6, 24, 46, 47, 48, 1, 49, 11, 50, 51, 27, 52, 28, 17, 8, 1, 18], [6, 24, 46, 47, 48, 1, 49, 11, 50, 51, 27, 52, 28, 17, 8, 1, 18, 4], [6, 24, 46, 47, 48, 1, 49, 11, 50, 51, 27, 52, 28, 17, 8, 1, 18, 4, 2], [6, 24, 46, 47, 48, 1, 49, 11, 50, 51, 27, 52, 28, 17, 8, 1, 18, 4, 2, 15], [6, 24, 46, 47, 48, 1, 49, 11, 50, 51, 27, 52, 28, 17, 8, 1, 18, 4, 2, 15, 1], [6, 24, 46, 47, 48, 1, 49, 11, 50, 51, 27, 52, 28, 17, 8, 1, 18, 4, 2, 15, 1, 5], [6, 24, 46, 47, 48, 1, 49, 11, 50, 51, 27, 52, 28, 17, 8, 1, 18, 4, 2, 15, 1, 5, 53], [2, 14], [2, 14, 10], [2, 14, 10, 16], [2, 14, 10, 16, 54], [2, 14, 10, 16, 54, 3], [2, 14, 10, 16, 54, 3, 55], [2, 14, 10, 16, 54, 3, 55, 56], [2, 14, 10, 16, 54, 3, 55, 56, 3], [2, 14, 10, 16, 54, 3, 55, 56, 3, 57], [2, 14, 10, 16, 54, 3, 55, 56, 3, 57, 58], [2, 14, 10, 16, 54, 3, 55, 56, 3, 57, 58, 59], [2, 14, 10, 16, 54, 3, 55, 56, 3, 57, 58, 59, 18], [2, 14, 10, 16, 54, 3, 55, 56, 3, 57, 58, 59, 18, 60], [2, 14, 10, 16, 54, 3, 55, 56, 3, 57, 58, 59, 18, 60, 11], [2, 14, 10, 16, 54, 3, 55, 56, 3, 57, 58, 59, 18, 60, 11, 61], [2, 14, 10, 16, 54, 3, 55, 56, 3, 57, 58, 59, 18, 60, 11, 61, 19], [2, 14, 10, 16, 54, 3, 55, 56, 3, 57, 58, 59, 18, 60, 11, 61, 19, 62], [2, 14, 10, 16, 54, 3, 55, 56, 3, 57, 58, 59, 18, 60, 11, 61, 19, 62, 8], [2, 14, 10, 16, 54, 3, 55, 56, 3, 57, 58, 59, 18, 60, 11, 61, 19, 62, 8, 6], [2, 14, 10, 16, 54, 3, 55, 56, 3, 57, 58, 59, 18, 60, 11, 61, 19, 62, 8, 6, 2], [2, 14, 10, 16, 54, 3, 55, 56, 3, 57, 58, 59, 18, 60, 11, 61, 19, 62, 8, 6, 2, 63], [2, 14, 10, 16, 54, 3, 55, 56, 3, 57, 58, 59, 18, 60, 11, 61, 19, 62, 8, 6, 2, 63, 64], [2, 14, 10, 16, 54, 3, 55, 56, 3, 57, 58, 59, 18, 60, 11, 61, 19, 62, 8, 6, 2, 63, 64, 1], [2, 14, 10, 16, 54, 3, 55, 56, 3, 57, 58, 59, 18, 60, 11, 61, 19, 62, 8, 6, 2, 63, 64, 1, 65], [66, 67], [66, 67, 11], [66, 67, 11, 25], [66, 67, 11, 25, 68], [66, 67, 11, 25, 68, 1], [66, 67, 11, 25, 68, 1, 69], [66, 67, 11, 25, 68, 1, 69, 2], [66, 67, 11, 25, 68, 1, 69, 2, 70], [66, 67, 11, 25, 68, 1, 69, 2, 70, 71], [66, 67, 11, 25, 68, 1, 69, 2, 70, 71, 3], [66, 67, 11, 25, 68, 1, 69, 2, 70, 71, 3, 2], [66, 67, 11, 25, 68, 1, 69, 2, 70, 71, 3, 2, 72], [66, 67, 11, 25, 68, 1, 69, 2, 70, 71, 3, 2, 72, 73], [66, 67, 11, 25, 68, 1, 69, 2, 70, 71, 3, 2, 72, 73, 74], [66, 67, 11, 25, 68, 1, 69, 2, 70, 71, 3, 2, 72, 73, 74, 8], [66, 67, 11, 25, 68, 1, 69, 2, 70, 71, 3, 2, 72, 73, 74, 8, 2], [66, 67, 11, 25, 68, 1, 69, 2, 70, 71, 3, 2, 72, 73, 74, 8, 2, 75], [66, 67, 11, 25, 68, 1, 69, 2, 70, 71, 3, 2, 72, 73, 74, 8, 2, 75, 19], [66, 67, 11, 25, 68, 1, 69, 2, 70, 71, 3, 2, 72, 73, 74, 8, 2, 75, 19, 76], [66, 67, 11, 25, 68, 1, 69, 2, 70, 71, 3, 2, 72, 73, 74, 8, 2, 75, 19, 76, 77], [66, 67, 11, 25, 68, 1, 69, 2, 70, 71, 3, 2, 72, 73, 74, 8, 2, 75, 19, 76, 77, 1], [66, 67, 11, 25, 68, 1, 69, 2, 70, 71, 3, 2, 72, 73, 74, 8, 2, 75, 19, 76, 77, 1, 78], [66, 67, 11, 25, 68, 1, 69, 2, 70, 71, 3, 2, 72, 73, 74, 8, 2, 75, 19, 76, 77, 1, 78, 17], [66, 67, 11, 25, 68, 1, 69, 2, 70, 71, 3, 2, 72, 73, 74, 8, 2, 75, 19, 76, 77, 1, 78, 17, 79], [66, 67, 11, 25, 68, 1, 69, 2, 70, 71, 3, 2, 72, 73, 74, 8, 2, 75, 19, 76, 77, 1, 78, 17, 79, 80], [66, 67, 11, 25, 68, 1, 69, 2, 70, 71, 3, 2, 72, 73, 74, 8, 2, 75, 19, 76, 77, 1, 78, 17, 79, 80, 81], [4, 82], [4, 82, 2], [4, 82, 2, 14], [4, 82, 2, 14, 16], [4, 82, 2, 14, 16, 83], [4, 82, 2, 14, 16, 83, 84], [4, 82, 2, 14, 16, 83, 84, 5], [4, 82, 2, 14, 16, 83, 84, 5, 1], [4, 82, 2, 14, 16, 83, 84, 5, 1, 85], [4, 82, 2, 14, 16, 83, 84, 5, 1, 85, 27], [4, 82, 2, 14, 16, 83, 84, 5, 1, 85, 27, 28], [4, 82, 2, 14, 16, 83, 84, 5, 1, 85, 27, 28, 17], [4, 82, 2, 14, 16, 83, 84, 5, 1, 85, 27, 28, 17, 8], [4, 82, 2, 14, 16, 83, 84, 5, 1, 85, 27, 28, 17, 8, 19], [4, 82, 2, 14, 16, 83, 84, 5, 1, 85, 27, 28, 17, 8, 19, 86], [4, 82, 2, 14, 16, 83, 84, 5, 1, 85, 27, 28, 17, 8, 19, 86, 4], [4, 82, 2, 14, 16, 83, 84, 5, 1, 85, 27, 28, 17, 8, 19, 86, 4, 5], [4, 82, 2, 14, 16, 83, 84, 5, 1, 85, 27, 28, 17, 8, 19, 86, 4, 5, 87], [4, 82, 2, 14, 16, 83, 84, 5, 1, 85, 27, 28, 17, 8, 19, 86, 4, 5, 87, 1], [4, 82, 2, 14, 16, 83, 84, 5, 1, 85, 27, 28, 17, 8, 19, 86, 4, 5, 87, 1, 88], [4, 82, 2, 14, 16, 83, 84, 5, 1, 85, 27, 28, 17, 8, 19, 86, 4, 5, 87, 1, 88, 6], [4, 82, 2, 14, 16, 83, 84, 5, 1, 85, 27, 28, 17, 8, 19, 86, 4, 5, 87, 1, 88, 6, 8], [4, 82, 2, 14, 16, 83, 84, 5, 1, 85, 27, 28, 17, 8, 19, 86, 4, 5, 87, 1, 88, 6, 8, 1], [4, 82, 2, 14, 16, 83, 84, 5, 1, 85, 27, 28, 17, 8, 19, 86, 4, 5, 87, 1, 88, 6, 8, 1, 18], [4, 82, 2, 14, 16, 83, 84, 5, 1, 85, 27, 28, 17, 8, 19, 86, 4, 5, 87, 1, 88, 6, 8, 1, 18, 89], [4, 82, 2, 14, 16, 83, 84, 5, 1, 85, 27, 28, 17, 8, 19, 86, 4, 5, 87, 1, 88, 6, 8, 1, 18, 89, 90], [4, 82, 2, 14, 16, 83, 84, 5, 1, 85, 27, 28, 17, 8, 19, 86, 4, 5, 87, 1, 88, 6, 8, 1, 18, 89, 90, 91], [4, 82, 2, 14, 16, 83, 84, 5, 1, 85, 27, 28, 17, 8, 19, 86, 4, 5, 87, 1, 88, 6, 8, 1, 18, 89, 90, 91, 2], [4, 82, 2, 14, 16, 83, 84, 5, 1, 85, 27, 28, 17, 8, 19, 86, 4, 5, 87, 1, 88, 6, 8, 1, 18, 89, 90, 91, 2, 92], [4, 93], [4, 93, 2], [4, 93, 2, 13], [4, 93, 2, 13, 3], [4, 93, 2, 13, 3, 94], [4, 93, 2, 13, 3, 94, 9], [4, 93, 2, 13, 3, 94, 9, 10], [4, 93, 2, 13, 3, 94, 9, 10, 95], [4, 93, 2, 13, 3, 94, 9, 10, 95, 96], [4, 93, 2, 13, 3, 94, 9, 10, 95, 96, 15], [4, 93, 2, 13, 3, 94, 9, 10, 95, 96, 15, 1], [4, 93, 2, 13, 3, 94, 9, 10, 95, 96, 15, 1, 5], [4, 93, 2, 13, 3, 94, 9, 10, 95, 96, 15, 1, 5, 26], [4, 93, 2, 13, 3, 94, 9, 10, 95, 96, 15, 1, 5, 26, 97], [4, 93, 2, 13, 3, 94, 9, 10, 95, 96, 15, 1, 5, 26, 97, 98], [4, 93, 2, 13, 3, 94, 9, 10, 95, 96, 15, 1, 5, 26, 97, 98, 1], [4, 93, 2, 13, 3, 94, 9, 10, 95, 96, 15, 1, 5, 26, 97, 98, 1, 99], [4, 93, 2, 13, 3, 94, 9, 10, 95, 96, 15, 1, 5, 26, 97, 98, 1, 99, 11], [4, 93, 2, 13, 3, 94, 9, 10, 95, 96, 15, 1, 5, 26, 97, 98, 1, 99, 11, 100], [4, 93, 2, 13, 3, 94, 9, 10, 95, 96, 15, 1, 5, 26, 97, 98, 1, 99, 11, 100, 1], [4, 93, 2, 13, 3, 94, 9, 10, 95, 96, 15, 1, 5, 26, 97, 98, 1, 99, 11, 100, 1, 101]]\n"
     ]
    }
   ],
   "source": [
    "def CreateInput(text_data):\n",
    "    input_sequences = []\n",
    "    for line in text_data:\n",
    "        token_list = tokenizer.texts_to_sequences([line])[0]\n",
    "        for i in range(1, len(token_list)):\n",
    "            n_gram_sequence = token_list[:i+1]\n",
    "            input_sequences.append(n_gram_sequence)\n",
    "    return input_sequences\n",
    "input_sequences=CreateInput(text_data)\n",
    "print(input_sequences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.4.Convert to full vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_sequence_len = max([len(seq) for seq in input_sequences])\n",
    "input_sequences = np.array(pad_sequences(input_sequences, maxlen=max_sequence_len, padding='pre'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.5 Divide the data set into training set and testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = input_sequences[:, :-1], input_sequences[:, -1]\n",
    "y =to_categorical(y, num_classes=total_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3 RNN Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1 Configuration RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(total_words, 10, name='embedding_layer')) \n",
    "model.add(SimpleRNN(8, return_sequences=True, activation=relu, name='rnn_layer_1'))\n",
    "model.add(SimpleRNN(9, return_sequences=True, activation=relu, name='rnn_layer_2'))\n",
    "model.add(SimpleRNN(9, activation=relu, name='rnn_layer_3'))\n",
    "model.add(Dense(total_words, activation='softmax', name='output_layer'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2. Trainning RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 15ms/step - accuracy: 0.0117 - loss: 4.6258\n",
      "Epoch 2/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.0141 - loss: 4.6221   \n",
      "Epoch 3/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.0750 - loss: 4.6181\n",
      "Epoch 4/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.0558 - loss: 4.6153\n",
      "Epoch 5/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.1242 - loss: 4.6098\n",
      "Epoch 6/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.0826 - loss: 4.6060\n",
      "Epoch 7/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.1117 - loss: 4.6012\n",
      "Epoch 8/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.0639 - loss: 4.5929\n",
      "Epoch 9/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.1027 - loss: 4.5845\n",
      "Epoch 10/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.0950 - loss: 4.5707\n",
      "Epoch 11/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.0838 - loss: 4.5545\n",
      "Epoch 12/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.0548 - loss: 4.5191\n",
      "Epoch 13/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.0454 - loss: 4.4554\n",
      "Epoch 14/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.0332 - loss: 4.3514   \n",
      "Epoch 15/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.0523 - loss: 4.2919\n",
      "Epoch 16/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.0702 - loss: 4.3058\n",
      "Epoch 17/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.0894 - loss: 4.2529\n",
      "Epoch 18/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.1469 - loss: 4.0897\n",
      "Epoch 19/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.1104 - loss: 4.1553\n",
      "Epoch 20/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.0973 - loss: 4.0782\n",
      "Epoch 21/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.0989 - loss: 4.0582\n",
      "Epoch 22/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.0767 - loss: 4.0882   \n",
      "Epoch 23/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.1072 - loss: 3.9318\n",
      "Epoch 24/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.1114 - loss: 3.8860\n",
      "Epoch 25/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.1459 - loss: 3.8240\n",
      "Epoch 26/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.1182 - loss: 3.8547\n",
      "Epoch 27/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.1160 - loss: 3.8047\n",
      "Epoch 28/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.1320 - loss: 3.7626\n",
      "Epoch 29/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.1107 - loss: 3.8153\n",
      "Epoch 30/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.1402 - loss: 3.7953\n",
      "Epoch 31/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.1365 - loss: 3.7685\n",
      "Epoch 32/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.1253 - loss: 3.8099\n",
      "Epoch 33/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.1004 - loss: 3.8191\n",
      "Epoch 34/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.1045 - loss: 3.7403\n",
      "Epoch 35/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.1258 - loss: 3.6957\n",
      "Epoch 36/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.1669 - loss: 3.6008\n",
      "Epoch 37/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.1385 - loss: 3.6188\n",
      "Epoch 38/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.1202 - loss: 3.6473\n",
      "Epoch 39/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.1488 - loss: 3.4305\n",
      "Epoch 40/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.1359 - loss: 3.6132\n",
      "Epoch 41/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.1660 - loss: 3.4982\n",
      "Epoch 42/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.1576 - loss: 3.4535\n",
      "Epoch 43/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.1739 - loss: 3.4241\n",
      "Epoch 44/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.1709 - loss: 3.3326\n",
      "Epoch 45/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.2060 - loss: 3.2190\n",
      "Epoch 46/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.2170 - loss: 3.1734\n",
      "Epoch 47/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.2197 - loss: 3.1802\n",
      "Epoch 48/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.2059 - loss: 3.2070\n",
      "Epoch 49/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.2067 - loss: 3.1299\n",
      "Epoch 50/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.2286 - loss: 3.1630\n",
      "Epoch 51/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.2542 - loss: 3.0259\n",
      "Epoch 52/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.2007 - loss: 3.0615\n",
      "Epoch 53/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.2209 - loss: 3.0109\n",
      "Epoch 54/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.2435 - loss: 3.0317\n",
      "Epoch 55/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.2400 - loss: 2.9103\n",
      "Epoch 56/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.2713 - loss: 2.8236\n",
      "Epoch 57/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.2661 - loss: 2.8497\n",
      "Epoch 58/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.3238 - loss: 2.7221\n",
      "Epoch 59/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.2914 - loss: 2.6906\n",
      "Epoch 60/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.3231 - loss: 2.6775\n",
      "Epoch 61/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.3351 - loss: 2.5763\n",
      "Epoch 62/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.3573 - loss: 2.3656\n",
      "Epoch 63/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.3271 - loss: 2.5154\n",
      "Epoch 64/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.3647 - loss: 2.4677\n",
      "Epoch 65/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.3826 - loss: 2.2847\n",
      "Epoch 66/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.3915 - loss: 2.3275\n",
      "Epoch 67/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.4274 - loss: 2.2307\n",
      "Epoch 68/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.3990 - loss: 2.2485\n",
      "Epoch 69/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.4503 - loss: 2.1967\n",
      "Epoch 70/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.4171 - loss: 2.1146\n",
      "Epoch 71/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.4263 - loss: 2.1596\n",
      "Epoch 72/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.4262 - loss: 2.1406\n",
      "Epoch 73/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.4055 - loss: 2.1219\n",
      "Epoch 74/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.4130 - loss: 2.1265\n",
      "Epoch 75/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 55ms/step - accuracy: 0.4567 - loss: 2.0264\n",
      "Epoch 76/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.4590 - loss: 2.0182\n",
      "Epoch 77/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.4789 - loss: 1.9325\n",
      "Epoch 78/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.5092 - loss: 1.8687\n",
      "Epoch 79/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5071 - loss: 1.9030\n",
      "Epoch 80/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.5566 - loss: 1.7147\n",
      "Epoch 81/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.4963 - loss: 1.7747\n",
      "Epoch 82/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.5018 - loss: 1.8216\n",
      "Epoch 83/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5095 - loss: 1.8725\n",
      "Epoch 84/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.5577 - loss: 1.6452\n",
      "Epoch 85/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.5493 - loss: 1.6768\n",
      "Epoch 86/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.5576 - loss: 1.6107\n",
      "Epoch 87/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.5622 - loss: 1.5906\n",
      "Epoch 88/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.5539 - loss: 1.5580\n",
      "Epoch 89/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.6121 - loss: 1.4457\n",
      "Epoch 90/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5872 - loss: 1.5115\n",
      "Epoch 91/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.6233 - loss: 1.4519\n",
      "Epoch 92/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.5986 - loss: 1.4205\n",
      "Epoch 93/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6279 - loss: 1.4420\n",
      "Epoch 94/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.5867 - loss: 1.5099\n",
      "Epoch 95/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6295 - loss: 1.3916\n",
      "Epoch 96/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.6111 - loss: 1.4519\n",
      "Epoch 97/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.6331 - loss: 1.3722\n",
      "Epoch 98/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.5989 - loss: 1.3632\n",
      "Epoch 99/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.6696 - loss: 1.3102\n",
      "Epoch 100/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.6757 - loss: 1.2512\n",
      "Epoch 101/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.6815 - loss: 1.2180\n",
      "Epoch 102/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.6688 - loss: 1.2641\n",
      "Epoch 103/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.6377 - loss: 1.2582\n",
      "Epoch 104/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.7121 - loss: 1.1405\n",
      "Epoch 105/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.7065 - loss: 1.1618\n",
      "Epoch 106/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.7734 - loss: 0.9851\n",
      "Epoch 107/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.6914 - loss: 1.1863\n",
      "Epoch 108/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.7208 - loss: 1.1748\n",
      "Epoch 109/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.7497 - loss: 1.0490\n",
      "Epoch 110/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.7135 - loss: 1.0894\n",
      "Epoch 111/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.7649 - loss: 1.0351\n",
      "Epoch 112/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.7268 - loss: 1.0107\n",
      "Epoch 113/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.7497 - loss: 0.9855\n",
      "Epoch 114/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.7670 - loss: 0.9694\n",
      "Epoch 115/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.7512 - loss: 1.0632\n",
      "Epoch 116/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.6759 - loss: 1.0721\n",
      "Epoch 117/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.7261 - loss: 1.0794\n",
      "Epoch 118/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.7419 - loss: 1.0229\n",
      "Epoch 119/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.7535 - loss: 0.9396\n",
      "Epoch 120/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.7578 - loss: 1.0540\n",
      "Epoch 121/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.7662 - loss: 0.9510\n",
      "Epoch 122/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.7658 - loss: 0.9221\n",
      "Epoch 123/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.7776 - loss: 0.9529\n",
      "Epoch 124/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.7853 - loss: 0.9245\n",
      "Epoch 125/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.7953 - loss: 0.8675\n",
      "Epoch 126/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.8462 - loss: 0.7406\n",
      "Epoch 127/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.7964 - loss: 0.8411\n",
      "Epoch 128/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.7719 - loss: 0.9889\n",
      "Epoch 129/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.7477 - loss: 1.0325\n",
      "Epoch 130/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.7909 - loss: 0.8563\n",
      "Epoch 131/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.8089 - loss: 0.8430\n",
      "Epoch 132/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.8303 - loss: 0.7133\n",
      "Epoch 133/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.7926 - loss: 0.8501\n",
      "Epoch 134/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.7968 - loss: 0.8374\n",
      "Epoch 135/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.8383 - loss: 0.7434\n",
      "Epoch 136/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.8018 - loss: 0.7895\n",
      "Epoch 137/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.8146 - loss: 0.7616\n",
      "Epoch 138/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.8154 - loss: 0.8025\n",
      "Epoch 139/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.8384 - loss: 0.7271\n",
      "Epoch 140/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.8020 - loss: 0.7406\n",
      "Epoch 141/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.8403 - loss: 0.7556\n",
      "Epoch 142/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8104 - loss: 0.8281\n",
      "Epoch 143/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.8032 - loss: 0.8185\n",
      "Epoch 144/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8408 - loss: 0.7309\n",
      "Epoch 145/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8310 - loss: 0.7072\n",
      "Epoch 146/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.8242 - loss: 0.6836\n",
      "Epoch 147/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.8231 - loss: 0.6859\n",
      "Epoch 148/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8374 - loss: 0.6915\n",
      "Epoch 149/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8390 - loss: 0.6878\n",
      "Epoch 150/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8510 - loss: 0.6382\n",
      "Epoch 151/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.8520 - loss: 0.6457\n",
      "Epoch 152/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.8354 - loss: 0.6191\n",
      "Epoch 153/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.8937 - loss: 0.5104\n",
      "Epoch 154/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.8413 - loss: 0.6525\n",
      "Epoch 155/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8327 - loss: 0.7573\n",
      "Epoch 156/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.8757 - loss: 0.5971\n",
      "Epoch 157/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8758 - loss: 0.5634\n",
      "Epoch 158/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.8833 - loss: 0.5486\n",
      "Epoch 159/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.8575 - loss: 0.5829\n",
      "Epoch 160/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.8782 - loss: 0.5046\n",
      "Epoch 161/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8551 - loss: 0.6172\n",
      "Epoch 162/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.8690 - loss: 0.5733\n",
      "Epoch 163/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8506 - loss: 0.6163\n",
      "Epoch 164/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.8751 - loss: 0.6439\n",
      "Epoch 165/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.8789 - loss: 0.5909\n",
      "Epoch 166/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.8579 - loss: 0.5737\n",
      "Epoch 167/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.7989 - loss: 0.7136\n",
      "Epoch 168/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.7800 - loss: 0.7685\n",
      "Epoch 169/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.7687 - loss: 0.8503\n",
      "Epoch 170/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7671 - loss: 0.8287\n",
      "Epoch 171/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.7590 - loss: 0.7219\n",
      "Epoch 172/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.8589 - loss: 0.6572\n",
      "Epoch 173/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.8599 - loss: 0.6070\n",
      "Epoch 174/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.8695 - loss: 0.5973\n",
      "Epoch 175/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.8776 - loss: 0.5920\n",
      "Epoch 176/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.8811 - loss: 0.5436\n",
      "Epoch 177/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8920 - loss: 0.4925\n",
      "Epoch 178/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.8765 - loss: 0.5255\n",
      "Epoch 179/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.8884 - loss: 0.4921\n",
      "Epoch 180/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.8874 - loss: 0.5032\n",
      "Epoch 181/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8615 - loss: 0.5596\n",
      "Epoch 182/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.8842 - loss: 0.5273\n",
      "Epoch 183/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.8825 - loss: 0.5473\n",
      "Epoch 184/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9037 - loss: 0.4291\n",
      "Epoch 185/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8948 - loss: 0.5120\n",
      "Epoch 186/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9077 - loss: 0.4789\n",
      "Epoch 187/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9251 - loss: 0.4503\n",
      "Epoch 188/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9059 - loss: 0.4416\n",
      "Epoch 189/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8890 - loss: 0.4654\n",
      "Epoch 190/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9042 - loss: 0.4473\n",
      "Epoch 191/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9149 - loss: 0.4529\n",
      "Epoch 192/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.9432 - loss: 0.3778\n",
      "Epoch 193/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.8917 - loss: 0.4420\n",
      "Epoch 194/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9226 - loss: 0.4495\n",
      "Epoch 195/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9119 - loss: 0.4629\n",
      "Epoch 196/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.8906 - loss: 0.4707\n",
      "Epoch 197/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9156 - loss: 0.4235\n",
      "Epoch 198/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9228 - loss: 0.3659\n",
      "Epoch 199/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9129 - loss: 0.3795\n",
      "Epoch 200/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9183 - loss: 0.3833\n",
      "Epoch 201/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9202 - loss: 0.4190\n",
      "Epoch 202/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9154 - loss: 0.3957\n",
      "Epoch 203/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.8957 - loss: 0.4710\n",
      "Epoch 204/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9274 - loss: 0.3440\n",
      "Epoch 205/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9063 - loss: 0.4135\n",
      "Epoch 206/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9003 - loss: 0.4487\n",
      "Epoch 207/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9038 - loss: 0.4193\n",
      "Epoch 208/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.8785 - loss: 0.5356\n",
      "Epoch 209/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.8938 - loss: 0.4328\n",
      "Epoch 210/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.8079 - loss: 0.6135\n",
      "Epoch 211/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.8576 - loss: 0.5179\n",
      "Epoch 212/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.8762 - loss: 0.5057\n",
      "Epoch 213/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.8154 - loss: 0.6159\n",
      "Epoch 214/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.8622 - loss: 0.5333\n",
      "Epoch 215/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.8758 - loss: 0.4467\n",
      "Epoch 216/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.8916 - loss: 0.4885\n",
      "Epoch 217/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.8818 - loss: 0.4839\n",
      "Epoch 218/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8722 - loss: 0.4397\n",
      "Epoch 219/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9117 - loss: 0.3632\n",
      "Epoch 220/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9104 - loss: 0.4102\n",
      "Epoch 221/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9178 - loss: 0.3712\n",
      "Epoch 222/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9339 - loss: 0.3401\n",
      "Epoch 223/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9164 - loss: 0.3811\n",
      "Epoch 224/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9180 - loss: 0.3757\n",
      "Epoch 225/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9312 - loss: 0.3303\n",
      "Epoch 226/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9298 - loss: 0.3340\n",
      "Epoch 227/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9221 - loss: 0.3324\n",
      "Epoch 228/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9214 - loss: 0.3477\n",
      "Epoch 229/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9493 - loss: 0.2752\n",
      "Epoch 230/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9410 - loss: 0.3124\n",
      "Epoch 231/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9446 - loss: 0.3178\n",
      "Epoch 232/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.9270 - loss: 0.3328\n",
      "Epoch 233/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9264 - loss: 0.3509\n",
      "Epoch 234/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9356 - loss: 0.2741\n",
      "Epoch 235/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9245 - loss: 0.3372\n",
      "Epoch 236/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9309 - loss: 0.3158\n",
      "Epoch 237/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9521 - loss: 0.2790\n",
      "Epoch 238/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9429 - loss: 0.2801\n",
      "Epoch 239/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9447 - loss: 0.2549\n",
      "Epoch 240/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9172 - loss: 0.3851\n",
      "Epoch 241/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9094 - loss: 0.3702\n",
      "Epoch 242/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9278 - loss: 0.2941\n",
      "Epoch 243/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9533 - loss: 0.2432\n",
      "Epoch 244/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9367 - loss: 0.3139\n",
      "Epoch 245/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9251 - loss: 0.3162\n",
      "Epoch 246/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9547 - loss: 0.2498\n",
      "Epoch 247/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9406 - loss: 0.2478\n",
      "Epoch 248/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9474 - loss: 0.2537\n",
      "Epoch 249/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9536 - loss: 0.2617\n",
      "Epoch 250/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9610 - loss: 0.2226\n",
      "Epoch 251/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9434 - loss: 0.2647\n",
      "Epoch 252/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9510 - loss: 0.2670\n",
      "Epoch 253/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9488 - loss: 0.2453\n",
      "Epoch 254/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9334 - loss: 0.3293\n",
      "Epoch 255/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9524 - loss: 0.2404\n",
      "Epoch 256/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.9392 - loss: 0.2495\n",
      "Epoch 257/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9587 - loss: 0.2491\n",
      "Epoch 258/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9286 - loss: 0.3022\n",
      "Epoch 259/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9272 - loss: 0.2847\n",
      "Epoch 260/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.9601 - loss: 0.2489\n",
      "Epoch 261/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9604 - loss: 0.2098\n",
      "Epoch 262/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9598 - loss: 0.2309\n",
      "Epoch 263/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9409 - loss: 0.2819\n",
      "Epoch 264/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9607 - loss: 0.2128\n",
      "Epoch 265/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9413 - loss: 0.2340\n",
      "Epoch 266/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9260 - loss: 0.3187\n",
      "Epoch 267/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.9226 - loss: 0.3054\n",
      "Epoch 268/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9438 - loss: 0.2553\n",
      "Epoch 269/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.8997 - loss: 0.3075\n",
      "Epoch 270/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8835 - loss: 0.3935\n",
      "Epoch 271/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9159 - loss: 0.3434\n",
      "Epoch 272/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8645 - loss: 0.4802\n",
      "Epoch 273/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.8827 - loss: 0.4192\n",
      "Epoch 274/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.8862 - loss: 0.5226\n",
      "Epoch 275/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8619 - loss: 0.3946\n",
      "Epoch 276/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8966 - loss: 0.3654\n",
      "Epoch 277/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9157 - loss: 0.3445\n",
      "Epoch 278/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9348 - loss: 0.3066\n",
      "Epoch 279/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9187 - loss: 0.3664\n",
      "Epoch 280/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.9459 - loss: 0.2722\n",
      "Epoch 281/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9476 - loss: 0.2553\n",
      "Epoch 282/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9548 - loss: 0.2603\n",
      "Epoch 283/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9551 - loss: 0.2330\n",
      "Epoch 284/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9534 - loss: 0.2368\n",
      "Epoch 285/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9596 - loss: 0.2195\n",
      "Epoch 286/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9386 - loss: 0.2752\n",
      "Epoch 287/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9611 - loss: 0.2006\n",
      "Epoch 288/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9446 - loss: 0.2661\n",
      "Epoch 289/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9614 - loss: 0.1975\n",
      "Epoch 290/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9420 - loss: 0.2609\n",
      "Epoch 291/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9470 - loss: 0.2322\n",
      "Epoch 292/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9574 - loss: 0.1845\n",
      "Epoch 293/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9411 - loss: 0.2537\n",
      "Epoch 294/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9412 - loss: 0.2343\n",
      "Epoch 295/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9537 - loss: 0.2042\n",
      "Epoch 296/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9540 - loss: 0.2061\n",
      "Epoch 297/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9658 - loss: 0.1766\n",
      "Epoch 298/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9669 - loss: 0.1949\n",
      "Epoch 299/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9583 - loss: 0.1922\n",
      "Epoch 300/300\n",
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9626 - loss: 0.2215\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1bbee4675d0>"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.fit(X, y, epochs=300, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3 Model Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_10\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_10\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">34</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,020</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ rnn_layer_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SimpleRNN</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">34</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)          │           <span style=\"color: #00af00; text-decoration-color: #00af00\">152</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ rnn_layer_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SimpleRNN</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">34</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>)          │           <span style=\"color: #00af00; text-decoration-color: #00af00\">162</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ rnn_layer_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SimpleRNN</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">171</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ output_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">102</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,020</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_layer (\u001b[38;5;33mEmbedding\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m34\u001b[0m, \u001b[38;5;34m10\u001b[0m)         │         \u001b[38;5;34m1,020\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ rnn_layer_1 (\u001b[38;5;33mSimpleRNN\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m34\u001b[0m, \u001b[38;5;34m8\u001b[0m)          │           \u001b[38;5;34m152\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ rnn_layer_2 (\u001b[38;5;33mSimpleRNN\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m34\u001b[0m, \u001b[38;5;34m9\u001b[0m)          │           \u001b[38;5;34m162\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ rnn_layer_3 (\u001b[38;5;33mSimpleRNN\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m)              │           \u001b[38;5;34m171\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ output_layer (\u001b[38;5;33mDense\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m102\u001b[0m)            │         \u001b[38;5;34m1,020\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">7,577</span> (29.60 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m7,577\u001b[0m (29.60 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,525</span> (9.86 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,525\u001b[0m (9.86 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,052</span> (19.74 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m5,052\u001b[0m (19.74 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.4 Predicting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 706ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 231ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step\n",
      "In short, the University of Technical Education is an ideal learning and research environment where creativity and discovery are awakened\n",
      "['learning', 'and', 'research', 'environment', 'where', 'creativity', 'and', 'discovery', 'are', 'awakened']\n"
     ]
    }
   ],
   "source": [
    "next_words = 10\n",
    "seed_text=\"In short, the University of Technical Education is an ideal\"\n",
    "y_predict=[]\n",
    "def Recommend(seed_text):\n",
    "    for _ in range(next_words):\n",
    "        token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
    "        token_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
    "        predicted_probs = model.predict(token_list)\n",
    "        predicted_word = tokenizer.index_word[np.argmax(predicted_probs)]\n",
    "        seed_text += \" \" + predicted_word\n",
    "        y_predict.append(predicted_word)\n",
    "    return seed_text\n",
    "y_result=Recommend(seed_text)\n",
    "print(y_result)\n",
    "print(y_predict)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.5 Evaluating "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0000\n",
      "Precision: 1.0000\n",
      "Recall: 1.0000\n",
      "F1-score: 1.0\n"
     ]
    }
   ],
   "source": [
    "y_true = [\"learning\",\"and\",\"research\" ,\"environment\",\"where\",\"creativity\",\"and\",\"discovery\",\"are\",\"awakened\"]\n",
    "accuracy = accuracy_score(y_true, y_predict)\n",
    "print(f'Accuracy: {accuracy:.4f}')\n",
    "\n",
    "precision = precision_score(y_true, y_predict, average='weighted')\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "\n",
    "recall = recall_score(y_true, y_predict, average='weighted')\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "\n",
    "f1score = f1_score(y_true, y_predict, average='weighted')\n",
    "print(f\"F1-score: {f1score}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "machinelearning-lTTH8rYd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
